{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69578ea9-7668-4764-9dd9-fc00f7b3a87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.0.1+cu117\n",
      "Fri Jul 28 15:22:19 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.43.04    Driver Version: 515.43.04    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-DGXS...  On   | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   33C    P0    51W / 300W |    511MiB / 16384MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-DGXS...  On   | 00000000:08:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    50W / 300W |   5835MiB / 16384MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-DGXS...  On   | 00000000:0E:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    37W / 300W |      4MiB / 16384MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-DGXS...  On   | 00000000:0F:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    36W / 300W |      4MiB / 16384MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     19822      C   python                            483MiB |\n",
      "|    0   N/A  N/A     40642      G   /usr/lib/xorg/Xorg                  9MiB |\n",
      "|    0   N/A  N/A     40678      G   /usr/bin/gnome-shell               14MiB |\n",
      "|    1   N/A  N/A     17102      C   ...poshnikov/env/bin/python3     5831MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "print(f\"Torch version: {torch.__version__}\")\n",
    "os.system(\"nvidia-smi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1eb42f6a-c00e-4e63-9173-362103cebdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CFG:\n",
    "    embedding_dim: int = field(default=256)\n",
    "    head_dim: int = field(default=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ce3c705-0c2f-4dc5-9331-5f61c775e744",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_cfg = CFG()\n",
    "embeddim = base_cfg.embedding_dim\n",
    "headdim =  base_cfg.head_dim\n",
    "\n",
    "tokens = torch.randn(1, 5, embeddim)\n",
    "Q_latent = torch.randn(embeddim, headdim) / math.sqrt(embeddim)\n",
    "K_latent = torch.randn(embeddim, headdim) / math.sqrt(embeddim)\n",
    "V_latent = torch.randn(embeddim, embeddim) / math.sqrt(embeddim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dee40e4-f117-4301-a571-25f083a1f933",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = torch.einsum(\"BTE, EH -> BTH\", tokens, Q_latent)\n",
    "K = torch.einsum(\"BTE, EH -> BTH\", tokens, K_latent)\n",
    "V = torch.einsum(\"BTE, EF -> BTF\", tokens, V_latent)\n",
    "scores = torch.einsum(\"BTH, BSH -> BTS\", Q, K)\n",
    "attn = torch.nn.functional.softmax(scores / math.sqrt(headdim), dim=-1)\n",
    "\n",
    "result = torch.einsum(\"BST, BTF -> BSF\", attn, V)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad61f6f0-abbf-4646-8f06-655739043424",
   "metadata": {},
   "source": [
    "### Same is done in PyTorch wrapper around CUDA kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d300a0e-6f9f-4313-a8c4-6e7e40ae241e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "attn_torch = F.scaled_dot_product_attention(Q, K, V)\n",
    "torch.allclose(attn_torch, result, atol=1E-6, rtol=1E-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d36ac085-f629-4ce6-b089-08ed8cf6e435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 256])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_torch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb94a94-cc06-4870-abda-5a7aa2df4cec",
   "metadata": {},
   "source": [
    "### Doing MHA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d20856d3-d97f-46f7-be1d-f067acc00eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 768\n",
    "num_heads = 12 # 768 // 12 = 64 - each head operating on 64-dim vector space\n",
    "headdim = embedding_dim // num_heads\n",
    "\n",
    "tokens = torch.randn(1, 5, embedding_dim)\n",
    "Q_latent = torch.randn(embedding_dim, headdim * num_heads) / math.sqrt(embedding_dim)\n",
    "K_latent = torch.randn(embedding_dim, headdim * num_heads) / math.sqrt(embedding_dim)\n",
    "V_latent = torch.randn(embedding_dim, headdim * num_heads) / math.sqrt(embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a660686-061e-4791-8308-c2a45f798176",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install einops -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c747541a-5cc4-4e9f-a998-51ce2636f040",
   "metadata": {},
   "outputs": [],
   "source": [
    "import einops\n",
    "\n",
    "Q = torch.einsum(\"BTE, EH -> BTH\", tokens, Q_latent)\n",
    "K = torch.einsum(\"BTE, EH -> BTH\", tokens, K_latent)\n",
    "V = torch.einsum(\"BTE, EF -> BTF\", tokens, V_latent)\n",
    "\n",
    "Q_mh = einops.rearrange(Q, \"B T (heads headdim) -> B T heads headdim\", heads=num_heads, headdim=headdim)\n",
    "K_mh = einops.rearrange(K, \"B T (heads headdim) -> B T heads headdim\", heads=num_heads, headdim=headdim)\n",
    "V_mh = einops.rearrange(V, \"B T (heads headdim) -> B T heads headdim\", heads=num_heads, headdim=headdim)\n",
    "\n",
    "scores_mh = torch.einsum(\"BTHD, BSHD -> BHTS\", Q_mh, K_mh)\n",
    "attmath_mh = F.softmax(scores_mh / math.sqrt(headdim), dim=-1)\n",
    "result = torch.einsum(\"BHTS, BTHD -> BHTD\", attmath_mh, V_mh) # B heads tokens embed_dim (for each head)\n",
    "result = einops.rearrange(result, \"B H T D -> B T (H D)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2e81696-1dcf-4fcd-980c-2e5de517a153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 768])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bb46fc-1b86-4fd2-9d7f-4d77139e6102",
   "metadata": {},
   "source": [
    "### Torch version of MHA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e3d61445-207d-40d7-96e2-a78f75ede0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mha = nn.MultiheadAttention(embedding_dim, num_heads, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d3b54320-a953-4e1f-9c13-f78ac5c09b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2304, 768])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mha.in_proj_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "191f75fa-1bb3-4d23-9c6a-532d9379314e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0000e+00, -1.0000e-04, -1.0000e-04, -1.0000e-04, -1.0000e-04],\n",
      "        [-0.0000e+00, -0.0000e+00, -1.0000e-04, -1.0000e-04, -1.0000e-04],\n",
      "        [-0.0000e+00, -0.0000e+00, -0.0000e+00, -1.0000e-04, -1.0000e-04],\n",
      "        [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -1.0000e-04],\n",
      "        [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "attn_mask = -1E-4 * torch.triu(torch.ones(tokens.shape[1], tokens.shape[1]), 1)\n",
    "print(attn_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "282eb4b2-67d3-48a7-a294-2f316b69d689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.1252, -0.2225, -0.0994,  ..., -0.2800, -0.0930, -0.3960],\n",
       "          [ 0.1050, -0.1977, -0.1301,  ..., -0.3278,  0.0305, -0.3866],\n",
       "          [ 0.1150, -0.1873, -0.1067,  ..., -0.1942,  0.0123, -0.2534],\n",
       "          [ 0.2343, -0.2250, -0.1684,  ..., -0.3058, -0.1578, -0.2287],\n",
       "          [ 0.2323, -0.2044, -0.1477,  ..., -0.3364, -0.1396, -0.2945]]],\n",
       "        grad_fn=<TransposeBackward0>),\n",
       " tensor([[[0.2313, 0.1711, 0.1839, 0.1844, 0.2293],\n",
       "          [0.1671, 0.1977, 0.1935, 0.1976, 0.2442],\n",
       "          [0.1922, 0.1974, 0.1754, 0.1853, 0.2497],\n",
       "          [0.1930, 0.2019, 0.2351, 0.1927, 0.1773],\n",
       "          [0.1794, 0.2096, 0.2178, 0.1780, 0.2152]]], grad_fn=<MeanBackward1>))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mha(tokens, tokens, tokens, attn_mask=attn_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255ad569-69b0-4d59-950e-637b6406c8af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5547825-fa75-48aa-ad06-07deb00bc81d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02130444-2c6e-45c6-b277-8cd1b46e1649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04f5577-071c-48a7-89b8-a6509a179865",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
